{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_image_classifier_cpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTrLWlBrOI+4iGHomkB77Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gapple95/machine_learning/blob/master/colab_image_classifier_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10IAUP7FjOg",
        "outputId": "bc6bef86-ee47-4c6b-e616-384e6fc4548a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import time as t #시간 측정용\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
        "print(\"GPU name : \",tf.test.gpu_device_name())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.3.0\n",
            "Hub version: 0.9.0\n",
            "WARNING:tensorflow:From <ipython-input-2-02b6aca52030>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n",
            "GPU name :  /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQR_H0pJGh2K"
      },
      "source": [
        "설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMrDLGchGcjC",
        "outputId": "0ec24c67-9826-42e6-cdcf-8719b6aac5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "module_selection = (\"mobilenet_v2_100_224\", 224) \n",
        "handle_base, pixels = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "\n",
        "BATCH_SIZE = 32 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4 with input size (224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRUJW-DrGkLx"
      },
      "source": [
        "TF2 모델 모듈 갖고오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crrre71MG0JS",
        "outputId": "21b574ca-fcef-4c21-afcf-abe19c04cf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6OZ-q4G1cx",
        "outputId": "15a0aa92-9bd9-4fdf-9f39-a456dc126b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False \n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 731 images belonging to 5 classes.\n",
            "Found 2939 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OR8DwblIGfj"
      },
      "source": [
        "데이터 갖고오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3OgIdORH5r9",
        "outputId": "40d59b49-d3d1-4635-f000-6ef45c73ec1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "do_fine_tuning = False \n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    # Explicitly define the input shape so the model can be properly\n",
        "    # loaded by the TFLiteConverter\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMIfQtt-IAgM"
      },
      "source": [
        "모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orrvsvfYJFK7",
        "outputId": "d101a272-7a79-43dd-a69c-21f0a2cc7c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "  steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "  validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "  hist = model.fit(\n",
        "      train_generator,\n",
        "      epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "      validation_data=valid_generator,\n",
        "      validation_steps=validation_steps).history"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "91/91 [==============================] - 100s 1s/step - loss: 0.9231 - accuracy: 0.7558 - val_loss: 0.7388 - val_accuracy: 0.8594\n",
            "Epoch 2/5\n",
            "91/91 [==============================] - 99s 1s/step - loss: 0.6915 - accuracy: 0.8734 - val_loss: 0.6878 - val_accuracy: 0.8778\n",
            "Epoch 3/5\n",
            "91/91 [==============================] - 99s 1s/step - loss: 0.6587 - accuracy: 0.8965 - val_loss: 0.6891 - val_accuracy: 0.8849\n",
            "Epoch 4/5\n",
            "91/91 [==============================] - 99s 1s/step - loss: 0.6184 - accuracy: 0.9150 - val_loss: 0.6695 - val_accuracy: 0.8807\n",
            "Epoch 5/5\n",
            "91/91 [==============================] - 98s 1s/step - loss: 0.6066 - accuracy: 0.9278 - val_loss: 0.6844 - val_accuracy: 0.8665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKGfVJReJg1X"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,  \n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwmzFbK8Ibmh"
      },
      "source": [
        "모델 훈련"
      ]
    }
  ]
}